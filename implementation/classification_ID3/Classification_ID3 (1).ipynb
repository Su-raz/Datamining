{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Dataset"
      ],
      "metadata": {
        "id": "h5c4__6NqWHj"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QaiQ7yxgD02w"
      },
      "outputs": [],
      "source": [
        "# Step 1: Dataset explore\n",
        "# https://www.kaggle.com/tareqjoy/trainplaytennis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "pCqR2dsypEaL"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = pd.read_csv(\"/content/playtennis.csv\")\n",
        "dataset.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "Citd_wc_pKba",
        "outputId": "ce79eb18-c118-4450-aab9-2bd500d24c18"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Outlook Temperature Humidity    Wind Play Tennis\n",
              "0     Sunny         Hot     High    Weak          No\n",
              "1     Sunny         Hot     High  Strong          No\n",
              "2  Overcast         Hot     High    Weak         Yes\n",
              "3      Rain        Mild     High    Weak         Yes\n",
              "4      Rain        Cool   Normal    Weak         Yes"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f5061db4-3b9d-449c-85ea-eeb7b9cf5faf\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Outlook</th>\n",
              "      <th>Temperature</th>\n",
              "      <th>Humidity</th>\n",
              "      <th>Wind</th>\n",
              "      <th>Play Tennis</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Sunny</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Strong</td>\n",
              "      <td>No</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Overcast</td>\n",
              "      <td>Hot</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Mild</td>\n",
              "      <td>High</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Rain</td>\n",
              "      <td>Cool</td>\n",
              "      <td>Normal</td>\n",
              "      <td>Weak</td>\n",
              "      <td>Yes</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5061db4-3b9d-449c-85ea-eeb7b9cf5faf')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f5061db4-3b9d-449c-85ea-eeb7b9cf5faf button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f5061db4-3b9d-449c-85ea-eeb7b9cf5faf');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-f10bcc27-57d7-40a0-9622-0db371b14e31\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f10bcc27-57d7-40a0-9622-0db371b14e31')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-f10bcc27-57d7-40a0-9622-0db371b14e31 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset",
              "summary": "{\n  \"name\": \"dataset\",\n  \"rows\": 14,\n  \"fields\": [\n    {\n      \"column\": \"Outlook\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Sunny\",\n          \"Overcast\",\n          \"Rain\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Temperature\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Hot\",\n          \"Mild\",\n          \"Cool\"\n        ],\n        \"num_unique_values\": 3,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Humidity\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Normal\",\n          \"High\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Wind\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Strong\",\n          \"Weak\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Play Tennis\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"samples\": [\n          \"Yes\",\n          \"No\"\n        ],\n        \"num_unique_values\": 2,\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the entropy of the whole dataset"
      ],
      "metadata": {
        "id": "mypQ8170qToU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In mathematics, we had to calculate the entropy of the whole dataset first like below:\n",
        "\n",
        "    Total row = 14\n",
        "    Row with \"Yes\" class = 9\n",
        "    Row with \"No\" class = 5Complete entropy of dataset is -\n",
        "    H(S) = - p(Yes) * log2(p(Yes)) - p(No) * log2(p(No))\n",
        "        = - (9/14) * log2(9/14) - (5/14) * log2(5/14)\n",
        "        = - (-0.41) - (-0.53)\n",
        "        = 0.94\n",
        "\n",
        "So, here we will do the same as the above equation.\n",
        "\n",
        "**Method description:**\n",
        "Calculates the entropy of the whole dataset.\n",
        "\n",
        "    train_data: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No]).\n",
        "    returns: float, calculated entropy of the whole dataframe (=0.94)\n",
        "\n"
      ],
      "metadata": {
        "id": "TNWYBaYGqg9C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_total_entropy(train_data, label, class_list):\n",
        "    total_row = train_data.shape[0] #the total size of the dataset\n",
        "    total_entropy = 0\n",
        "\n",
        "    for c in class_list: #for each class in the label\n",
        "        total_class_count = train_data[train_data[label] == c].shape[0] #number of the class\n",
        "        total_class_entr = - (total_class_count/total_row)*np.log2(total_class_count/total_row) #entropy of the class\n",
        "        total_entropy += total_class_entr #adding the class entropy to the total entropy of the dataset\n",
        "\n",
        "    return total_entropy"
      ],
      "metadata": {
        "id": "JX158MrLqaYM"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating the entropy for the filtered dataset\n",
        "\n",
        "Using the table of step 1, The mathematics calculation will be like below for the feature Outlook:\n",
        "\n",
        "Categorical values of Outlook - Sunny, Overcast and RainTotal count of row containing:\n",
        "\n",
        "    Sunny = 5\n",
        "    Sunny & Yes = 2\n",
        "    Sunny & No = 3>> H(Outlook=Sunny) = -(2/5)*log(2/5)-(3/5)*log(3/5) = 0.971\n",
        "    \n",
        "    Total count of row containing:  \n",
        "    Rain = 5\n",
        "    Rain & Yes = 3\n",
        "    Rain & No = 2>> H(Outlook=Rain) = -(3/5)*log(3/5)-(2/5)*log(2/5) = 0.971\n",
        "    \n",
        "    Total count of row containing:  \n",
        "    Overcast = 4\n",
        "    Overcast & Yes = 4\n",
        "    Overcast & No = 0>> H(Outlook=Overcast) = -(4/4)*log(4/4)-0 = 0\n",
        "\n",
        "Note: We have to do the same for all features like Wind, Humidity etc.\n",
        "The equivalent Python implementation will be like below:\n",
        "\n",
        "Method description:\n",
        "\n",
        "    Calculates entropy of a specific feature = value.\n",
        "    feature_value_data: a pandas dataframe, which contains data that has a specific value of a feature (Ex. Only data with Outlook = Sunny)\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No]).\n",
        "    returns: float, calculated entropy of the feature value dataframe (Ex. for Outlook = Sunny, returns 0.971)"
      ],
      "metadata": {
        "id": "RIDTqHAfrMz7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_entropy(feature_value_data, label, class_list):\n",
        "    class_count = feature_value_data.shape[0]\n",
        "    entropy = 0\n",
        "\n",
        "    for c in class_list:\n",
        "        label_class_count = feature_value_data[feature_value_data[label] == c].shape[0] #row count of class c\n",
        "        entropy_class = 0\n",
        "        if label_class_count != 0:\n",
        "            probability_class = label_class_count/class_count #probability of the class\n",
        "            entropy_class = - probability_class * np.log2(probability_class)  #entropy\n",
        "        entropy += entropy_class\n",
        "    return entropy"
      ],
      "metadata": {
        "id": "fMWLZp62rhaf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Calculating information gain for a feature\n",
        "\n",
        "After calculating entropy, we have to calculate the information gain of that feature. In math, first, we have to calculate the information of that feature like this: (for the feature Outlook)\n",
        "\n",
        "    I(Outlook)  = p(Sunny) * H(Outlook=Sunny) +\n",
        "                  p(Rain) * H(Outlook=Rain) +\n",
        "                  p(Overcast) * H(Outlook=Overcast)\n",
        "                = (5/14)*0.971 + (5/14)*0.971 + (4/14)*0\n",
        "                = 0.693\n",
        "\n",
        "Then, we have to subtract this from the total entropy of the dataset which is the information gain of the feature.\n",
        "\n",
        "    Information Gain  = H(S) - I(Outlook)\n",
        "                      = 0.94 - 0.693\n",
        "                      = 0.247\n",
        "\n",
        "In python we have done like this:\n",
        "\n",
        "**Method description:**\n",
        "\n",
        "Calculates information gain of a feature.\n",
        "\n",
        "    feature_name: string, the name of the feature that we want to find the information gain (Ex. Outlook)\n",
        "    train_data: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No]).\n",
        "    returns: calculated information gain of the feature (Ex. for Outlook, returns 0.247)"
      ],
      "metadata": {
        "id": "elqb5dAFs4hs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def calc_info_gain(feature_name, train_data, label, class_list):\n",
        "    feature_value_list = train_data[feature_name].unique() # unqiue values of the feature\n",
        "    total_row = train_data.shape[0]\n",
        "    feature_info = 0.0\n",
        "\n",
        "    for feature_value in feature_value_list:\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value] # filtering rows with that feature_value\n",
        "        feature_value_count = feature_value_data.shape[0]\n",
        "        feature_value_entropy = calc_entropy(feature_value_data, label, class_list) # calculcating entropy for the feature value\n",
        "        feature_value_probability = feature_value_count/total_row\n",
        "        feature_info += feature_value_probability * feature_value_entropy # calculating information of the feature value\n",
        "\n",
        "    return calc_total_entropy(train_data, label, class_list) - feature_info # calculating information gain by subtracting"
      ],
      "metadata": {
        "id": "x2SpD8U_s35d"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding the most informative feature (feature with highest information gain)\n",
        "\n",
        "Like Outlook feature, We have to calculate information gain for every feature in the dataset. Then we have to select the feature with the highest information gain. After calculating mathematically we will find the values like below:\n",
        "\n",
        "Information gain:\n",
        "\n",
        "    Outlook = 0.247 (Highest value)\n",
        "    Temperature = 0.0292\n",
        "    Humidity = 0.153\n",
        "    Wind = 0.048\n",
        "\n",
        "As the feature Outlook has the highest value, so it will be selected for our tree node.\n",
        "\n",
        "**Method description:**\n",
        "\n",
        "    Finds the most informative feature from the current dataset.\n",
        "    train_data: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No]).\n",
        "    returns: string, the feature name"
      ],
      "metadata": {
        "id": "_lzbnoiYuKQ6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def find_most_informative_feature(train_data, label, class_list):\n",
        "    feature_list = train_data.columns.drop(label) # finding the feature names in the dataset\n",
        "                                                  # N.B. label is not a feature, so dropping it\n",
        "    max_info_gain = -1\n",
        "    max_info_feature = None\n",
        "\n",
        "    for feature in feature_list: # for each feature in the dataset\n",
        "        feature_info_gain = calc_info_gain(feature, train_data, label, class_list)\n",
        "        if max_info_gain < feature_info_gain: # selecting feature name with highest information gain\n",
        "            max_info_gain = feature_info_gain\n",
        "            max_info_feature = feature\n",
        "\n",
        "    return max_info_feature"
      ],
      "metadata": {
        "id": "EEHGbYbnuWz5"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Adding a node to the tree\n",
        "\n",
        "As we have found the feature name with the highest information gain, we have to generate a node in the tree and its value as a branch. For example, we have selected **Outlook**, so we have to add **Outlook as a node in the tree** and its value **Sunny or Rain or Overcast as a branch**.\n",
        "\n",
        "Outlook is selected as Node.\n",
        "\n",
        "    (Outlook = Sunny): Not pure class, contains both class Yes and No\n",
        "    (Outlook = Overcast): Pure class, contains only one class Yes\n",
        "    (Outlook = Rain): Not pure class, contains both class Yes and No\n",
        "\n",
        "\n",
        "After selecting a pure class, we have to remove the rows from the dataset corresponding to the feature value. **Ex: we have to remove rows with Outlook = Overcast.** The resultant dataset will be updated.\n",
        "\n",
        "\n",
        "Method description:\n",
        "\n",
        "    Generates subtree of a feature and removes the feature = value from the dataset. The tree might contain ‘?’ as a value if the tree node isn’t a pure class.\n",
        "    feature_name: string, the name of the feature that we want to add to tree and shrink dataset (Ex. Outlook)\n",
        "    train_data: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No]).\n",
        "    returns: tuple (dictionary, dataframe), the tree node with it’s branches and the updated dataset"
      ],
      "metadata": {
        "id": "Trug1B9iv7Rz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_sub_tree(feature_name, train_data, label, class_list):\n",
        "    feature_value_count_dict = train_data[feature_name].value_counts(sort=False) #dictionary of the count of unqiue feature value\n",
        "    tree = {} #sub tree or node\n",
        "\n",
        "    for feature_value, count in feature_value_count_dict.iteritems():\n",
        "        feature_value_data = train_data[train_data[feature_name] == feature_value] #dataset with only feature_name = feature_value\n",
        "\n",
        "        assigned_to_node = False #flag for tracking feature_value is pure class or not\n",
        "        for c in class_list: #for each class\n",
        "            class_count = feature_value_data[feature_value_data[label] == c].shape[0] #count of class c\n",
        "\n",
        "            if class_count == count: #count of (feature_value = count) of class (pure class)\n",
        "                tree[feature_value] = c #adding node to the tree\n",
        "                train_data = train_data[train_data[feature_name] != feature_value] #removing rows with feature_value\n",
        "                assigned_to_node = True\n",
        "        if not assigned_to_node: #not pure class\n",
        "            tree[feature_value] = \"?\" #as feature_value is not a pure class, it should be expanded further,\n",
        "                                      #so the branch is marking with ?\n",
        "\n",
        "    return tree, train_data"
      ],
      "metadata": {
        "id": "FZWUb4TTxEGV"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##  Performing ID3 Algorithm and generating Tree\n",
        "\n",
        "The overall step is:\n",
        "\n",
        "    Finding the most informative feature\n",
        "    Making a tree node with a feature name and feature values as branches\n",
        "    - If pure class, adding leaf node (= Class) to the tree node\n",
        "    - If impure class, adding an expandable node (= ‘?’) to the tree node\n",
        "    Shrinking/Updating the dataset according to the pure class\n",
        "    Adding the node with branches into a tree\n",
        "    Expand the branch of the next impure class (= ‘?’) with an updated dataset\n",
        "\n",
        "The recursion endpoint:\n",
        "\n",
        "    The dataset becomes empty after updating\n",
        "    There is no expandable branch (= all pure class)\n",
        "\n",
        "**Method description:**\n",
        "\n",
        "Generates a tree using dictionary of dictionaries. The leaf node of the tree would be value of a feature = class name. The resultant tree is returned by reference.\n",
        "\n",
        "    root: dictionary, which will contain the resultant tree through recursive subtree, initially it should be an empty dictionary, after the recursive calls it should contain the result\n",
        "    prev_feature_value: Any datatype (Int or Float or String etc.) depending on the datatype of the previous feature, the previous value of the pointed node/feature, initially it should be None\n",
        "    train_data: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    class_list: list, unique classes of the label (=[Yes, No])\n",
        "    returns: None"
      ],
      "metadata": {
        "id": "txeGNi0UxHzm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_tree(root, prev_feature_value, train_data, label, class_list):\n",
        "    if train_data.shape[0] != 0: #if dataset becomes enpty after updating\n",
        "        max_info_feature = find_most_informative_feature(train_data, label, class_list) #most informative feature\n",
        "        tree, train_data = generate_sub_tree(max_info_feature, train_data, label, class_list) #getting tree node and updated dataset\n",
        "        next_root = None\n",
        "\n",
        "        if prev_feature_value != None: #add to intermediate node of the tree\n",
        "            root[prev_feature_value] = dict()\n",
        "            root[prev_feature_value][max_info_feature] = tree\n",
        "            next_root = root[prev_feature_value][max_info_feature]\n",
        "        else: #add to root of the tree\n",
        "            root[max_info_feature] = tree\n",
        "            next_root = root[max_info_feature]\n",
        "\n",
        "        for node, branch in list(next_root.items()): #iterating the tree node\n",
        "            if branch == \"?\": #if it is expandable\n",
        "                feature_value_data = train_data[train_data[max_info_feature] == node] #using the updated dataset\n",
        "                make_tree(next_root, node, feature_value_data, label, class_list) #recursive call with updated dataset"
      ],
      "metadata": {
        "id": "rOMNcpYexiWG"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Finding unique classes of the label and Starting the algorithm\n",
        "\n",
        "We can start calling the recursive tree building algorithm of ID3 after finding the class names.\n",
        "\n",
        "**Method description:** Generates id3 tree.\n",
        "    \n",
        "    train_data_m: a pandas dataframe\n",
        "    label: string, name of the label of the dataframe (=Play Tennis)\n",
        "    returns: (nested) dictionary, the decision tree"
      ],
      "metadata": {
        "id": "sccoe-JfxqK0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def id3(train_data_m, label):\n",
        "    train_data = train_data_m.copy() #getting a copy of the dataset\n",
        "    tree = {} #tree which will be updated\n",
        "    class_list = train_data[label].unique() #getting unqiue classes of the label\n",
        "    make_tree(tree, None, train_data, label, class_list) #start calling recursion\n",
        "    return tree"
      ],
      "metadata": {
        "id": "a7iRWZc6xo27"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tree = id3(dataset, 'Play Tennis')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8scA-ov2x9y8",
        "outputId": "1c848a27-841b-480e-c1f8-4fbd62325bb4"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-9-b182bf0ec406>:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for feature_value, count in feature_value_count_dict.iteritems():\n",
            "<ipython-input-9-b182bf0ec406>:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for feature_value, count in feature_value_count_dict.iteritems():\n",
            "<ipython-input-9-b182bf0ec406>:5: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
            "  for feature_value, count in feature_value_count_dict.iteritems():\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tree"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZIMOkPIyyFd4",
        "outputId": "e12b1a5c-edc9-4203-b3e7-f4e5fe334c69"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Outlook': {'Sunny': {'Humidity': {'High': 'No', 'Normal': 'Yes'}},\n",
              "  'Overcast': 'Yes',\n",
              "  'Rain': {'Wind': {'Weak': 'Yes', 'Strong': 'No'}}}}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pydot\n",
        "\n",
        "def draw(parent_name, child_name):\n",
        "    edge = pydot.Edge(parent_name, child_name)\n",
        "    graph.add_edge(edge)\n",
        "\n",
        "def visit(node, parent=None):\n",
        "    for k,v in node.items():# If using python3, use node.items() instead of node.iteritems()\n",
        "        if isinstance(v, dict):\n",
        "            # We start with the root node whose parent is None\n",
        "            # we don't want to graph the None node\n",
        "            if parent:\n",
        "                draw(parent, k)\n",
        "            visit(v, k)\n",
        "        else:\n",
        "            draw(parent, k)\n",
        "            # drawing the label using a distinct name\n",
        "            draw(k, k+'_'+v)\n",
        "\n",
        "graph = pydot.Dot(graph_type='graph')\n",
        "visit(tree)\n",
        "graph.write_png('decision_tree.png')"
      ],
      "metadata": {
        "id": "mkHISo7d3jWJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Predicting from the tree\n",
        "\n",
        "We have generated the tree. Now, we can use the tree for prediction. We will recursively traverse the nested dictionary until any leaf node (= class) is found. Remember that, the key of the dictionary is feature name which is the datatype of string, and the value is either a dictionary which means we have to traverse the tree more or any basic datatype like string or int or float depending on the class data type, which means it’s a leaf node.\n",
        "\n",
        "If we want to predict Outlook = `Rain` and Wind = `Strong` we have to traverse the dictionary like that:"
      ],
      "metadata": {
        "id": "wdHWja33yasN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(tree, instance):\n",
        "    if not isinstance(tree, dict): #if it is leaf node\n",
        "        return tree #return the value\n",
        "    else:\n",
        "        root_node = next(iter(tree)) #getting first key/feature name of the dictionary\n",
        "        feature_value = instance[root_node] #value of the feature\n",
        "        if feature_value in tree[root_node]: #checking the feature value in current tree node\n",
        "            return predict(tree[root_node][feature_value], instance) #goto next feature\n",
        "        else:\n",
        "            return None"
      ],
      "metadata": {
        "id": "R3KlPW1pyaFj"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation\n",
        "\n",
        "To evaluate the model i.e. the tree we need a labeled test dataset. Then after predicting we can calculate the difference of actual and predicted value in percentage.\n",
        "\n",
        "**Method description:**     Evaluates the accuracy of a id3 tree by testing against the expected result\n",
        "\n",
        "    tree: dictionary (of dictionaries), a decision tree\n",
        "    test_data_m: a pandas dataframe/test dataset\n",
        "    returns: float, the accuracy of the tree"
      ],
      "metadata": {
        "id": "G8S3ko6ly7DH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(tree, test_data_m, label):\n",
        "    correct_preditct = 0\n",
        "    wrong_preditct = 0\n",
        "    for index, row in test_data_m.iterrows(): #for each row in the dataset\n",
        "        result = predict(tree, test_data_m.iloc[index]) #predict the row\n",
        "        if result == test_data_m[label].iloc[index]: #predicted value and expected value is same or not\n",
        "            correct_preditct += 1 #increase correct count\n",
        "        else:\n",
        "            wrong_preditct += 1 #increase incorrect count\n",
        "    accuracy = correct_preditct / (correct_preditct + wrong_preditct) #calculating accuracy\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "i80ws6N2zLAd"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy = evaluate(tree, dataset, 'Play Tennis') #evaluating the test dataset\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vc2EXYWkzR4d",
        "outputId": "28962135-c6db-4310-f916-941bdc5f6761"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.0"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    }
  ]
}